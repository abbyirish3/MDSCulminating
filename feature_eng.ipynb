{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "df = pd.read_csv(\"data/influenza_data.csv\")\n",
    "\n",
    "# defin year and week in epi season\n",
    "df[\"year\"] = df[\"epiweek\"] // 100\n",
    "df[\"week\"] = df[\"epiweek\"] % 100\n",
    "\n",
    "# vectorized season definition (same as your apply)\n",
    "df[\"season\"] = df[\"year\"] - (df[\"week\"] < 30)\n",
    "\n",
    "# df by region (state vs. national)\n",
    "df_states = df[df[\"region\"].str.len() == 2].copy()\n",
    "df_nat = df[df[\"region\"] == \"nat\"].copy()\n",
    "\n",
    "# compute peak target \n",
    "peaks_states = (\n",
    "    df_states.groupby([\"season\", \"region\"])[\"wili\"]\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"wili\": \"peak_value\"})\n",
    ")\n",
    "\n",
    "peaks_nat = (\n",
    "    df_nat.groupby([\"season\", \"region\"])[\"wili\"]\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"wili\": \"peak_value\"})\n",
    ")\n",
    "\n",
    "all_peaks = pd.concat([peaks_states, peaks_nat], ignore_index=True)\n",
    "all_peaks = all_peaks[all_peaks[\"season\"] < 2025].copy()\n",
    "\n",
    "all_peaks.to_csv(\"data/target_peaks_wili.csv\", index=False)\n",
    "\n",
    "#  Combine states + nat for feature building \n",
    "df_use = pd.concat([df_states, df_nat], ignore_index=True)\n",
    "\n",
    "# keep seasons that exist in targets\n",
    "df_use = df_use[df_use[\"season\"] < 2025].copy()\n",
    "\n",
    "# sort for  time\n",
    "df_use = df_use.sort_values([\"region\", \"season\", \"epiweek\"]).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build minimal set of features\n",
    "df_use[\"y_t\"] = df_use[\"wili\"]\n",
    "\n",
    "# cumulative\n",
    "df_use[\"cum_y\"] = df_use.groupby([\"season\", \"region\"])[\"y_t\"].cumsum()\n",
    "\n",
    "# lags\n",
    "df_use[\"y_t_minus_1\"] = df_use.groupby([\"season\", \"region\"])[\"y_t\"].shift(1)\n",
    "df_use[\"y_t_minus_2\"] = df_use.groupby([\"season\", \"region\"])[\"y_t\"].shift(2)\n",
    "\n",
    "# differences: slope + accel-ish\n",
    "df_use[\"delta_1\"] = df_use[\"y_t\"] - df_use[\"y_t_minus_1\"]\n",
    "df_use[\"delta_2\"] = (df_use[\"y_t\"] - df_use[\"y_t_minus_1\"]) - (df_use[\"y_t_minus_1\"] - df_use[\"y_t_minus_2\"])\n",
    "\n",
    "# interactions: \"high and rising\"\n",
    "df_use[\"y_t_x_delta_1\"] = df_use[\"y_t\"] * df_use[\"delta_1\"]\n",
    "df_use[\"cum_y_x_delta_1\"] = df_use[\"cum_y\"] * df_use[\"delta_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season region  epiweek  week       y_t     cum_y  y_t_minus_1  y_t_minus_2  \\\n",
      "2    2010     ak   201042    42  0.586042  2.589458     1.128270     0.875146   \n",
      "3    2010     ak   201043    43  0.967742  3.557200     0.586042     1.128270   \n",
      "4    2010     ak   201044    44  0.683851  4.241051     0.967742     0.586042   \n",
      "5    2010     ak   201045    45  0.951904  5.192955     0.683851     0.967742   \n",
      "6    2010     ak   201046    46  0.962567  6.155522     0.951904     0.683851   \n",
      "\n",
      "    delta_1   delta_2  y_t_x_delta_1  cum_y_x_delta_1  peak_value  \n",
      "2 -0.542228 -0.795352      -0.317768        -1.404077      4.8801  \n",
      "3  0.381700  0.923928       0.369387         1.357783      4.8801  \n",
      "4 -0.283891 -0.665591      -0.194139        -1.203996      4.8801  \n",
      "5  0.268053  0.551944       0.255161         1.391987      4.8801  \n",
      "6  0.010663 -0.257390       0.010264         0.065636      4.8801  \n"
     ]
    }
   ],
   "source": [
    "# Merge target peaks onto every week row\n",
    "df_use = df_use.merge(all_peaks, on=[\"season\", \"region\"], how=\"left\")\n",
    "\n",
    "# model dataframe -- drop early rows without lag history\n",
    "feature_cols = [\n",
    "    \"y_t\", \"cum_y\", \"y_t_minus_1\", \"y_t_minus_2\",\n",
    "    \"delta_1\", \"delta_2\",\n",
    "    \"y_t_x_delta_1\", \"cum_y_x_delta_1\"\n",
    "]\n",
    "\n",
    "model_df = df_use.dropna(subset=feature_cols + [\"peak_value\"]).copy()\n",
    "\n",
    "# keep columns neededd for model only\n",
    "keep_cols = [\"season\", \"region\", \"epiweek\", \"week\"] + feature_cols + [\"peak_value\"]\n",
    "model_df = model_df[keep_cols]\n",
    "\n",
    "model_df.to_csv(\"data/model_df_wili.csv\", index=False)\n",
    "\n",
    "print(model_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'region', 'epiweek', 'week', 'y_t', 'cum_y', 'y_t_minus_1',\n",
      "       'y_t_minus_2', 'delta_1', 'delta_2', 'y_t_x_delta_1', 'cum_y_x_delta_1',\n",
      "       'peak_value'],\n",
      "      dtype='object')\n",
      "peak_value\n",
      "1    763\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(model_df.columns)\n",
    "\n",
    "print(model_df.groupby([\"season\", \"region\"])[\"peak_value\"].nunique().value_counts().head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
